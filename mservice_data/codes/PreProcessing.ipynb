{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khdmcpoud1az",
        "outputId": "8b2b996c-e83f-4159-a33e-34987f8e8274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data cleaned and saved to 'cleaned_data.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from the CSV file\n",
        "file_path= '/content/CleanZeroValDrop1.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Apply conditions to filter out outliers\n",
        "filtered_df = df[(df['plan_duration'] <= 200) & (df['actual_duration'] >= 0) & (df['actual_duration'] <= 500)]\n",
        "\n",
        "# Save the cleaned data to a new Excel file\n",
        "filtered_df.to_excel('/content/CleanZeroValDrop2.xlsx', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from category_encoders import BinaryEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel('/content/CleanZeroValDrop2.xlsx')\n",
        "\n",
        "# Apply Binary Encoding to 'Dealer' and 'Employee'\n",
        "encoder_binary = BinaryEncoder(cols=['Dealer', 'Employee'])\n",
        "df_encoded = encoder_binary.fit_transform(df)\n",
        "\n",
        "# Apply Label Encoding to 'job_type'\n",
        "encoder_label = LabelEncoder()\n",
        "df_encoded['job_type'] = encoder_label.fit_transform(df['job_type'])\n",
        "\n",
        "# Save the DataFrame to a new Excel file\n",
        "df_encoded.to_excel('/content/Encoded.xlsx', index=False)\n",
        "\n",
        "print(\"Data has been encoded and saved to 'encoded_data.xlsx'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMx0ozkPkbiI",
        "outputId": "ebc42f30-5375-494e-bc84-03cb45ae4d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been encoded and saved to 'encoded_data.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel('/content/CleanZeroValDrop2.xlsx')\n",
        "\n",
        "# Apply One-Hot Encoding to 'Dealer' and 'Employee'\n",
        "df_encoded = pd.get_dummies(df, columns=['Dealer', 'Employee'])\n",
        "\n",
        "# Apply Label Encoding to 'job_type'\n",
        "encoder_label = LabelEncoder()\n",
        "df_encoded['job_type'] = encoder_label.fit_transform(df['job_type'])\n",
        "\n",
        "# Save the DataFrame to a new Excel file\n",
        "df_encoded.to_excel('/content/encoded1.xlsx', index=False)\n",
        "\n",
        "print(\"Data has been encoded and saved to 'encoded1.xlsx'.\")\n"
      ],
      "metadata": {
        "id": "l3LLujMkl3x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel('/content/CleanZeroValDrop2.xlsx')\n",
        "\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM3-2FTIDws4",
        "outputId": "255b73f0-19fe-4182-8c50-0fdead77398f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Dealer', 'Employee', 'job_type', 'plan_duration', 'actual_duration',\n",
            "       'actual_work', 'created_on_date_date', 'created_on_date_time',\n",
            "       'assigned_on_date_date', 'assigned_on_date_time',\n",
            "       'plan_start_date_date', 'plan_start_date_time', 'plan_finish_date_date',\n",
            "       'plan_finish_date_time', 'act_start_date_date', 'act_start_date_time',\n",
            "       'act_finish_date_date', 'act_finish_date_time'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of date-time pairs to combine\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel('/content/CleanZeroValDrop2.xlsx')\n",
        "date_time_pairs = [\n",
        "    ('created_on_date_date', 'created_on_date_time'),\n",
        "    ('assigned_on_date_date', 'assigned_on_date_time'),\n",
        "    ('plan_start_date_date', 'plan_start_date_time'),\n",
        "    ('plan_finish_date_date', 'plan_finish_date_time'),\n",
        "    ('act_start_date_date', 'act_start_date_time'),\n",
        "    ('act_finish_date_date', 'act_finish_date_time')\n",
        "]\n",
        "\n",
        "# Combine date and time columns into single datetime columns\n",
        "for date_col, time_col in date_time_pairs:\n",
        "    combined_col_name = date_col.replace('_date', '')  # New name for the combined column\n",
        "    df[combined_col_name] = pd.to_datetime(df[date_col].astype(str) + ' ' + df[time_col].astype(str))\n",
        "    df.drop([date_col, time_col], axis=1, inplace=True)  # Drop the original date and time columns\n",
        "\n",
        "# Example of further datetime manipulation: Extract year, month, day, etc.\n",
        "# You can extract these from any of the new datetime columns\n",
        "df['year'] = df['created_on'].dt.year\n",
        "df['month'] = df['created_on'].dt.month\n",
        "df['day'] = df['created_on'].dt.day\n",
        "df['hour'] = df['created_on'].dt.hour\n",
        "df['minute'] = df['created_on'].dt.minute\n",
        "\n",
        "# Save the processed data\n",
        "df_encoded.to_excel('/content/preprocessed.xlsx', index=False)"
      ],
      "metadata": {
        "id": "qCkibnSyFJvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_excel('/content/preprocessed.xlsx')\n",
        " # Apply Label Encoding to 'job_type'\n",
        "encoder_label = LabelEncoder()\n",
        "df_encoded['job_type'] = encoder_label.fit_transform(df['job_type'])\n",
        "\n",
        "# Save the DataFrame to a new Excel file\n",
        "df_encoded.to_excel('/content/preprocessed1.xlsx', index=False)"
      ],
      "metadata": {
        "id": "OpCDEZhuKNSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel('/content/preprocessed1.xlsx')  # Update the path to your file\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SJJveTwmM4j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the format if the automatic parsing fails\n",
        "date_format = '%Y-%m-%d %H:%M:%S'\n",
        "\n",
        "# Combine date and time columns\n",
        "df['created_on'] = pd.to_datetime(df['created_on_date_date'].astype(str) + ' ' + df['created_on_date_time'].astype(str), format=date_format)\n",
        "df['assigned_on'] = pd.to_datetime(df['assigned_on_date_date'].astype(str) + ' ' + df['assigned_on_date_time'].astype(str), format=date_format)\n",
        "df['plan_start'] = pd.to_datetime(df['plan_start_date_date'].astype(str) + ' ' + df['plan_start_date_time'].astype(str), format=date_format)\n",
        "df['plan_finish'] = pd.to_datetime(df['plan_finish_date_date'].astype(str) + ' ' + df['plan_finish_date_time'].astype(str), format=date_format)\n",
        "df['act_start'] = pd.to_datetime(df['act_start_date_date'].astype(str) + ' ' + df['act_start_date_time'].astype(str), format=date_format)\n",
        "df['act_finish'] = pd.to_datetime(df['act_finish_date_date'].astype(str) + ' ' + df['act_finish_date_time'].astype(str), format=date_format)\n",
        "\n",
        "# Drop the original date and time columns\n",
        "df.drop(['created_on_date_date', 'created_on_date_time', 'assigned_on_date_date', 'assigned_on_date_time',\n",
        "         'plan_start_date_date', 'plan_start_date_time', 'plan_finish_date_date', 'plan_finish_date_time',\n",
        "         'act_start_date_date', 'act_start_date_time', 'act_finish_date_date', 'act_finish_date_time'], axis=1, inplace=True)\n",
        "\n",
        "# Save the DataFrame to a new Excel file\n",
        "df_encoded.to_excel('/content/preprocessed2.xlsx', index=False)\n",
        "# Check the new dataframe\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du5grUZONqVg",
        "outputId": "695c2287-ffe3-4c5d-efae-cb8e6c1ada7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dealer_0  Dealer_1  Dealer_2  Dealer_3  Dealer_4  Dealer_5  Dealer_6  \\\n",
            "0         0         0         0         0         0         0         1   \n",
            "1         0         0         0         0         0         0         1   \n",
            "2         0         0         0         0         0         0         1   \n",
            "3         0         0         0         0         0         0         1   \n",
            "4         0         0         0         0         0         0         1   \n",
            "\n",
            "   Employee_0  Employee_1  Employee_2  ...  job_type  plan_duration  \\\n",
            "0           0           0           0  ...        13              0   \n",
            "1           0           0           0  ...         8             24   \n",
            "2           0           0           0  ...         8             24   \n",
            "3           0           0           0  ...        11             24   \n",
            "4           0           0           0  ...        11             24   \n",
            "\n",
            "   actual_duration  actual_work          created_on         assigned_on  \\\n",
            "0              1.0          1.0 2018-01-13 13:27:00 2018-01-13 13:39:00   \n",
            "1              0.2          0.2 2018-01-15 11:14:00 2018-01-15 11:14:00   \n",
            "2              0.5          0.5 2018-01-16 10:20:00 2018-01-16 10:20:00   \n",
            "3              0.2          0.2 2018-01-17 10:01:00 2018-01-17 10:01:00   \n",
            "4              7.4          7.4 2018-01-17 14:46:00 2018-01-17 14:46:00   \n",
            "\n",
            "           plan_start         plan_finish           act_start  \\\n",
            "0 2018-01-13 13:27:00 2018-01-13 13:27:00 2018-01-13 13:45:00   \n",
            "1 2018-01-15 11:14:00 2018-01-16 11:14:00 2018-01-16 16:46:00   \n",
            "2 2018-01-16 10:20:00 2018-01-17 10:20:00 2018-01-16 12:07:00   \n",
            "3 2018-01-17 10:01:00 2018-01-18 10:01:00 2018-01-17 12:25:00   \n",
            "4 2018-01-17 14:46:00 2018-01-18 14:46:00 2018-01-17 14:46:00   \n",
            "\n",
            "           act_finish  \n",
            "0 2018-01-13 14:47:00  \n",
            "1 2018-01-16 16:59:00  \n",
            "2 2018-01-16 12:35:00  \n",
            "3 2018-01-17 12:37:00  \n",
            "4 2018-01-17 22:09:00  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the data (assuming previous steps are completed and saved to a new file)\n",
        "df = pd.read_excel('/content/preprocessed2.xlsx')\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Identify numerical columns - example based on typical data; adjust as necessary\n",
        "# This example assumes you want to scale all columns except datetime\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Apply scaling\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Check the scaled data\n",
        "print(df.head())\n",
        "\n",
        "# Save the scaled data\n",
        "df.to_excel('/content/preprocessed3.xlsx', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL81IyhhQwFN",
        "outputId": "425cab53-7fee-470c-cce0-f681a39a447d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dealer_0  Dealer_1  Dealer_2  Dealer_3  Dealer_4  Dealer_5  Dealer_6  \\\n",
            "0 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "1 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "2 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "3 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "4 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "\n",
            "   Employee_0  Employee_1  Employee_2  ...  assigned_on_date_date  \\\n",
            "0   -0.802487    -0.70414   -0.826832  ...             2018-01-13   \n",
            "1   -0.802487    -0.70414   -0.826832  ...             2018-01-15   \n",
            "2   -0.802487    -0.70414   -0.826832  ...             2018-01-16   \n",
            "3   -0.802487    -0.70414   -0.826832  ...             2018-01-17   \n",
            "4   -0.802487    -0.70414   -0.826832  ...             2018-01-17   \n",
            "\n",
            "   assigned_on_date_time  plan_start_date_date  plan_start_date_time  \\\n",
            "0               13:39:00            2018-01-13              13:27:00   \n",
            "1               11:14:00            2018-01-15              11:14:00   \n",
            "2               10:20:00            2018-01-16              10:20:00   \n",
            "3               10:01:00            2018-01-17              10:01:00   \n",
            "4               14:46:00            2018-01-17              14:46:00   \n",
            "\n",
            "   plan_finish_date_date  plan_finish_date_time  act_start_date_date  \\\n",
            "0             2018-01-13               13:27:00           2018-01-13   \n",
            "1             2018-01-16               11:14:00           2018-01-16   \n",
            "2             2018-01-17               10:20:00           2018-01-16   \n",
            "3             2018-01-18               10:01:00           2018-01-17   \n",
            "4             2018-01-18               14:46:00           2018-01-17   \n",
            "\n",
            "   act_start_date_time  act_finish_date_date  act_finish_date_time  \n",
            "0             13:45:00            2018-01-13              14:47:00  \n",
            "1             16:46:00            2018-01-16              16:59:00  \n",
            "2             12:07:00            2018-01-16              12:35:00  \n",
            "3             12:25:00            2018-01-17              12:37:00  \n",
            "4             14:46:00            2018-01-17              22:09:00  \n",
            "\n",
            "[5 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel('/content/preprocessed3.xlsx')\n",
        "\n",
        "# Specify the format if the automatic parsing fails\n",
        "date_format = '%Y-%m-%d %H:%M:%S'\n",
        "\n",
        "# Combine date and time columns\n",
        "df['created_on'] = pd.to_datetime(df['created_on_date_date'].astype(str) + ' ' + df['created_on_date_time'].astype(str), format=date_format)\n",
        "df['assigned_on'] = pd.to_datetime(df['assigned_on_date_date'].astype(str) + ' ' + df['assigned_on_date_time'].astype(str), format=date_format)\n",
        "df['plan_start'] = pd.to_datetime(df['plan_start_date_date'].astype(str) + ' ' + df['plan_start_date_time'].astype(str), format=date_format)\n",
        "df['plan_finish'] = pd.to_datetime(df['plan_finish_date_date'].astype(str) + ' ' + df['plan_finish_date_time'].astype(str), format=date_format)\n",
        "df['act_start'] = pd.to_datetime(df['act_start_date_date'].astype(str) + ' ' + df['act_start_date_time'].astype(str), format=date_format)\n",
        "df['act_finish'] = pd.to_datetime(df['act_finish_date_date'].astype(str) + ' ' + df['act_finish_date_time'].astype(str), format=date_format)\n",
        "\n",
        "# Drop the original date and time columns\n",
        "df.drop([\n",
        "    'created_on_date_date', 'created_on_date_time',\n",
        "    'assigned_on_date_date', 'assigned_on_date_time',\n",
        "    'plan_start_date_date', 'plan_start_date_time',\n",
        "    'plan_finish_date_date', 'plan_finish_date_time',\n",
        "    'act_start_date_date', 'act_start_date_time',\n",
        "    'act_finish_date_date', 'act_finish_date_time'\n",
        "], axis=1, inplace=True)\n",
        "\n",
        "# Save the DataFrame to a new Excel file\n",
        "df.to_excel('/content/processed4.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "8kxLrqNqUvIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_excel('/content/processed4.xlsx')\n",
        "# Assuming df is your DataFrame and 'created_on' is a datetime column\n",
        "df['created_on'] = pd.to_datetime(df['created_on'])\n",
        "# Extracting standard time-based features\n",
        "df['year'] = df['created_on'].dt.year\n",
        "df['month'] = df['created_on'].dt.month\n",
        "df['day'] = df['created_on'].dt.day\n",
        "df['weekday'] = df['created_on'].dt.weekday  # Monday=0, Sunday=6\n",
        "df['hour'] = df['created_on'].dt.hour\n",
        "df['minute'] = df['created_on'].dt.minute\n",
        "df['second'] = df['created_on'].dt.second\n",
        "df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)  # 1 for weekend, 0 for weekdays\n",
        "df['week_of_year'] = df['created_on'].dt.isocalendar().week  # Week of the year\n",
        "\n",
        "# Encoding 'hour' as a cyclic feature\n",
        "df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
        "df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
        "\n",
        "# Encoding 'month' as a cyclic feature\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['month']/12)\n",
        "\n",
        "# Encoding 'day' as a cyclic feature (assuming up to 31 days per month)\n",
        "df['day_sin'] = np.sin(2 * np.pi * df['day']/31)\n",
        "df['day_cos'] = np.cos(2 * np.pi * df['day']/31)\n",
        "\n",
        "# Encoding 'weekday' as a cyclic feature (7 days a week)\n",
        "df['weekday_sin'] = np.sin(2 * np.pi * df['weekday']/7)\n",
        "df['weekday_cos'] = np.cos(2 * np.pi * df['weekday']/7)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UskptUo5WoGB",
        "outputId": "b80f03e8-48ed-4b92-af70-227111b10d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dealer_0  Dealer_1  Dealer_2  Dealer_3  Dealer_4  Dealer_5  Dealer_6  \\\n",
            "0 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "1 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "2 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "3 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "4 -1.049048 -0.864957  -0.88694 -1.004894 -0.992457 -1.154276  1.181155   \n",
            "\n",
            "   Employee_0  Employee_1  Employee_2  ...  is_weekend  week_of_year  \\\n",
            "0   -0.802487    -0.70414   -0.826832  ...           1             2   \n",
            "1   -0.802487    -0.70414   -0.826832  ...           0             3   \n",
            "2   -0.802487    -0.70414   -0.826832  ...           0             3   \n",
            "3   -0.802487    -0.70414   -0.826832  ...           0             3   \n",
            "4   -0.802487    -0.70414   -0.826832  ...           0             3   \n",
            "\n",
            "   hour_sin  hour_cos  month_sin  month_cos   day_sin   day_cos  weekday_sin  \\\n",
            "0 -0.258819 -0.965926        0.5   0.866025  0.485302 -0.874347    -0.974928   \n",
            "1  0.258819 -0.965926        0.5   0.866025  0.101168 -0.994869     0.000000   \n",
            "2  0.500000 -0.866025        0.5   0.866025 -0.101168 -0.994869     0.781831   \n",
            "3  0.500000 -0.866025        0.5   0.866025 -0.299363 -0.954139     0.974928   \n",
            "4 -0.500000 -0.866025        0.5   0.866025 -0.299363 -0.954139     0.974928   \n",
            "\n",
            "   weekday_cos  \n",
            "0    -0.222521  \n",
            "1     1.000000  \n",
            "2     0.623490  \n",
            "3    -0.222521  \n",
            "4    -0.222521  \n",
            "\n",
            "[5 rows x 45 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyKyEj3VajGH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}